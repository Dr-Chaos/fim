= Dealing with duplicates

Duplicate files are addressed by Fim in two different ways.

== Duplicates inside a Fim repository

Fim allow you to detect duplicates using the `fdup` command.

You can also remove them.

=== Find duplicates

Fim is able to display duplicates contained in a repository using the `fdup` (`find-duplicates`) command.
It displays the list of duplicate files. +
See it in action in <<simple-example.adoc#_search_for_duplicate_files,Search for duplicate files>>.

[source, bash]
----
$ fim fdup
----

If the current State is already commited, you can skip the workspace scanning phase with the `-l` option :

[source, bash]
----
$ fim fdup -l
----

=== Remove duplicates

You can remove duplicate files.

* Either interactive:

[source, bash]
----
$ fim rdup
----

â€¢ Or automatically preserving the first file in the list:

[source, bash]
----
$ fim rdup -y
----

In both cases, it is possible to use the current State as with `fdup` by adding the `-l` option:

[source, bash]
----
$ fim rdup -l
----

== Duplicates that are outside

Fim can delete duplicate files contained in another repository. +
It can be useful if you want to cleanup old backups that are no more synchronized and you want to be sure to not lose any files that could have been modified or added. +
It erases all files locally that already exist in the master workspace.

For example, `backup` is a copy of the repository named `source` :

[source, bash]
----
$ cd backup
$ fim rdup -m ../source
----

When the workspace to clean is remote, you can just copy the `.fim` in an empty directory and set it as parameter to the `-m` option of the `rdup` command

=== Simple duplicates removing

Here is a step by step example of duplicates removing.
For the purpose of this example we use small files.

You can try it yourself by using the https://github.com/evrignaud/fim/blob/master/samples/remove-duplicates-example.sh[`samples/remove-duplicates-example.sh`] script.

==== Create a source directory with some files in it

[source, bash]
------
~$ mkdir rdup-example
~$ cd rdup-example
~/rdup-example$ mkdir source
~/rdup-example$ cd source/
~/rdup-example/source$ for i in 01 02 03 04 05 06 07 08 09 10 ; do echo "New File $i" > file${i} ; done
~/rdup-example/source$ ls -la
total 48
drwxrwxr-x 2 evrignaud evrignaud 4096 mai   21 08:39 .
drwxrwxr-x 3 evrignaud evrignaud 4096 mai   21 08:39 ..
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file01
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file02
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file03
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file04
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file05
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file06
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file07
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file08
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file09
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file10
------

==== Initialize the Fim repository

[source, bash]
------
~/rdup-example/source$ fim init -y
No comment provided. You are going to initialize your repository using the default comment.
2016/05/21 08:39:12 - Info  - Scanning recursively local files, using 'full' mode and 4 threads
(Hash progress legend for files grouped 10 by 10: # > 1 GB, @ > 200 MB, O > 100 MB, 8 > 50 MB, o > 20 MB, . otherwise)
.
2016/05/21 08:39:12 - Info  - Scanned 10 files (120 bytes), hashed 120 bytes (avg 120 bytes/s), during 00:00:00

Added:            file01
Added:            file02
Added:            file03
Added:            file04
Added:            file05
Added:            file06
Added:            file07
Added:            file08
Added:            file09
Added:            file10

10 added
Repository initialized
------

==== Create a backup of this directory

[source, bash]
------
~/rdup-example/source$ cd ..
~/rdup-example$ cp -a source backup
------

==== Modify two files into the source directory and move two others

[source, bash]
------
~/rdup-example$ cd source/

~/rdup-example/source$ echo modif1 >> file02
~/rdup-example/source$ echo modif2 >> file04

~/rdup-example/source$ mkdir subdir
~/rdup-example/source$ mv file01 subdir
~/rdup-example/source$ mv file03 subdir

~/rdup-example/source$ ls -la
total 48
drwxrwxr-x 4 evrignaud evrignaud 4096 mai   21 08:39 .
drwxrwxr-x 4 evrignaud evrignaud 4096 mai   21 08:39 ..
-rw-rw-r-- 1 evrignaud evrignaud   19 mai   21 08:39 file02
-rw-rw-r-- 1 evrignaud evrignaud   19 mai   21 08:39 file04
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file05
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file06
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file07
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file08
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file09
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file10
drwxrwxr-x 3 evrignaud evrignaud 4096 mai   21 08:39 .fim
drwxrwxr-x 2 evrignaud evrignaud 4096 mai   21 08:39 subdir

~/rdup-example/source$ ls -la subdir
total 16
drwxrwxr-x 2 evrignaud evrignaud 4096 mai   21 08:39 .
drwxrwxr-x 4 evrignaud evrignaud 4096 mai   21 08:39 ..
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file01
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file03
------

==== Commit all the modifications

[source, bash]
------
~/rdup-example/source$ fim ci -s -c "Modifications"
2016/05/21 08:39:13 - Info  - Scanning recursively local files, using 'super-fast' mode and 4 threads
(Hash progress legend for files grouped 10 by 10: # > 1 GB, @ > 200 MB, O > 100 MB, 8 > 50 MB, o > 20 MB, . otherwise)
.
2016/05/21 08:39:13 - Info  - Scanned 10 files (134 bytes), hashed 134 bytes (avg 134 bytes/s), during 00:00:00

Comparing with the last committed state from 2016/05/21 08:39:12
Comment: Initial State

Content modified: file02
Content modified: file04
Renamed:          file01 -> subdir/file01
Renamed:          file03 -> subdir/file03

2 content modified, 2 renamed

Do you really want to commit (y/n/A)? y
2016/05/21 08:39:14 - Info  - Retrieving the missing hash for all the modified files, using 'full' mode and 4 threads
2016/05/21 08:39:14 - Info  - Scanned 4 files (62 bytes), hashed 62 bytes (avg 62 bytes/s), during 00:00:00
------

==== Remove the duplicates

[source, bash]
------
~/rdup-example/source$ cd ../backup/
~/rdup-example/backup$ fim rdup -m ../source
2016/05/21 08:39:14 - Info  - Searching for duplicate files using the ../source directory as master

2016/05/21 08:39:14 - Info  - Scanning recursively local files, using 'full' mode and 4 threads
(Hash progress legend for files grouped 10 by 10: # > 1 GB, @ > 200 MB, O > 100 MB, 8 > 50 MB, o > 20 MB, . otherwise)
.
2016/05/21 08:39:15 - Info  - Scanned 10 files (120 bytes), hashed 120 bytes (avg 120 bytes/s), during 00:00:00

'file01' is a duplicate of '../source/subdir/file01'
Do you really want to remove it (y/n/A)? y
  'file01' removed
'file03' is a duplicate of '../source/subdir/file03'
Do you really want to remove it (y/n/A)? y
  'file03' removed
'file05' is a duplicate of '../source/file05'
Do you really want to remove it (y/n/A)? A
  'file05' removed
'file06' is a duplicate of '../source/file06'
  'file06' removed
'file07' is a duplicate of '../source/file07'
  'file07' removed
'file08' is a duplicate of '../source/file08'
  'file08' removed
'file09' is a duplicate of '../source/file09'
  'file09' removed
'file10' is a duplicate of '../source/file10'
  'file10' removed

8 duplicate files found. 8 duplicate files removed
------

[IMPORTANT]
=====
When you are prompted with a question asking for (y/n/A) which means Yes, No, or All Yes. +
'All Yes' will reply Yes to all the remaining questions. You can see it in action above.
=====

==== Only the two modified files remains

[source, bash]
------
~/rdup-example/backup$ ls -la
total 20
drwxrwxr-x 3 evrignaud evrignaud 4096 mai   21 08:39 .
drwxrwxr-x 4 evrignaud evrignaud 4096 mai   21 08:39 ..
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file02
-rw-rw-r-- 1 evrignaud evrignaud   12 mai   21 08:39 file04
drwxrwxr-x 3 evrignaud evrignaud 4096 mai   21 08:39 .fim
------

=== Complex duplicates removing

Let say that you have:

* a directory with a big file tree that we will call the source location.
* other locations that contain some files that were copied long ago from this source location. We will call one those locations the backup location.

Now you want to cleanup the backup location from the files that are identical with the ones in the source location.
To find duplicates into the backup location we will use the hash located into the source `.fim` directory.
We will call master location the name of the directory where is this `.fim`. +
**Most of the time the master location is the source location.** +
If the source location is not reachable from the backup location, you just need to put a copy of the source `.fim` directory near the backup location.

[NOTE]
====
The backup location can contain also his own `.fim` directory. It will be ignored.
====

==== Step by step

* Go into the source location and ensure that all the hash are up to date:

[source, bash]
----
$ cd <source location>
$ fim ci -y -c "Content added"
----

* If the backup location cannot reach the source location (so master location is not the source location),
copy the `.fim` directory that is in the source location into a place near the backup location.

[source, bash]
----
$ cd <somewhere near the backup location>
$ mkdir <master location>
$ scp -rp <remote host>@<source location>/.fim <master location>
----

[IMPORTANT]
====
The source `.fim` directory can't be nested into the root folder of the backup location.
====

* Run the remove duplicates command. For this, go in the backup location.

[source, bash]
----
$ cd <backup location>
$ fim rdup -m <master location>
----

